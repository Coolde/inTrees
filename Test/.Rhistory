ruleExec0 <- extractRules(treeList,X)
ruleExec <- unique(ruleExec0)
length(ruleExec)
ruleMetric <- getRuleMetric(ruleExec,X,target) # measure rules
ruleMetric[1:3,]
lookup <- lookupRule(ruleMetric,c("X[,4]","X[,3]"))
lookup
lookup[1:3,]
ruleMetric <- pruneRule(ruleMetric,X,target)
ruleMetric[1:3,]
ix <- which(as.numeric(ruleMetric[,"freq"])>0.01 & as.numeric(ruleMetric[,"err"])< 0.4)
ruleMetric <- ruleMetric[ix,]
ruleMetric[1:3,]
learner <- buildLearner(ruleMetric,X,target)
learner
readableLearner <- presentRules(learner,colnames(X)) # present the rules with a more readable format
readableLearner
ruleMetric <- getRuleMetric(ruleExec0,X,target)
freqPattern <- getFreqPattern(ruleMetric)
freqPattern
library(xtable)
print(xtable(ruleMetric), include.rownames=FALSE)
ruleExec0 <- extractRules(treeList,X) # transform to R-executable conditions
ruleExec <- unique(ruleExec0) # unique rules
cat( paste("There are ", length(ruleExec), " unique conditions. \n",sep="") )
ruleMetric <- getRuleMetric(ruleExec,X,target) # measure rules
ruleMetric[1:2]
ruleMetric[1:2,]
rm(list=ls(all=TRUE));graphics.off()
library(inTrees)
library(randomForest); library(RRF); library(gbm); set.seed(1)
data(iris); X <- iris[,1:(ncol(iris)-1)]; target <- iris[,"Species"]
# res <- dataSimulate(1); X <- res$X; target <- res$target;
lists = list()
# measure user-defined conditions
myRule <- "X[,3] > 5 & X[,4] > 1"
measureRule(myRule,X,target)  # without providing the outcome of the condition
measureRule(myRule,X,target,"versicolor")  # providing the outcome of the condition
rf <- randomForest(X,as.factor(target),ntree=100) # random forest
lists[['rf']] <- RF2List(rf) # extract a list of trees
rrf <- RRF(X,as.factor(target),ntree=100) # regularized random forest
lists[['rrf']] <- RF2List(rrf)
gbmFit <- gbm(target~ ., data=cbind(X,target), n.tree = 100, # boosted trees
interaction.depth = 10,distribution="multinomial")
lists[['gbm']] <- GBM2List(gbmFit,X)
v <- c("rf","rrf","gbm")
v <- c("rf")
for(i in v){
treeList <- lists[[i]]
ruleExec0 <- extractRules(treeList,X) # transform to R-executable conditions
ruleExec <- unique(ruleExec0) # unique rules
cat( paste("There are ", length(ruleExec), " unique conditions. \n",sep="") )
ruleMetric <- getRuleMetric(ruleExec,X,target) # measure rules
lookup <- lookupRule(ruleMetric,c("X[,4]","X[,3]")) # look up rules including X[,4] and X[,3]
ruleMetric <- pruneRule(ruleMetric,X,target) # prune each rule
# selecting rules by threholds of frequency & error
ix <- which(as.numeric(ruleMetric[,"freq"])>0.01 & as.numeric(ruleMetric[,"err"])< 0.5)
ruleMetric <- ruleMetric[ix,]
ruleMetric <- selectRuleRRF(ruleMetric,X,target) # rule selection
learner <- buildLearner(ruleMetric,X,target) #build the simplified tree ensemble learner
pred <- applyLearner(learner,X) #appy learner to data
readableLearner <- presentRules(learner,colnames(X)) # present the rules with a more readable format
# print(readableLearner)
# -- frequent variable interactions or conditions in a tree ensemble
# NOTE: the calculation is based on ruleExec0 WITHOUT pruning or selection
ruleMetric <- getRuleMetric(ruleExec0,X,target)
freqPattern <- getFreqPattern(ruleMetric)
#ruleMetric <- getRuleMetric(freqPattern,X,target)
}
#format the rule and metrics as a table in latex code
library(xtable)
print(xtable(ruleMetric), include.rownames=FALSE)
print(xtable(readableLearner), include.rownames=FALSE)
dicretizeVector(target)
target
X
iris[1:2,]
X <- iris[,-1]; target <- iris[,"Sepal.Length"]
dicretizeVector(target)
target <- dicretizeVector(target) # discretize it into three levels with equal frenquency
rf <- randomForest(X,target,ntree=100) # random forest
X <- iris[,-1]; target <- iris[,"Sepal.Length"]
rf <- randomForest(X,target,ntree=100) # random forest
rf
target <- dicretizeVector(target)
ruleExec0 <- extractRules(RF2List(rf),X)
ruleExec <- unique(ruleExec0)
target <- dicretizeVector(target)
ruleMetric <- getRuleMetric(ruleExec,X,target)
ruleMetric
# --- transform regression rules to classification rules
# make Sepal.Length as the target, other as predictors
X <- iris[,-1]; target <- iris[,"Sepal.Length"]
rf <- randomForest(X,target,ntree=100) # random forest
ruleExec0 <- extractRules(RF2List(rf),X)
ruleExec <- unique(ruleExec0)
target <- dicretizeVector(target) # discretize it into three levels with equal frenquency
# methods for classification rules can then be used for
# the conditions extracted from the regression trees
ruleMetric <- getRuleMetric(ruleExec,X,target)
ruleMetric
sourceDir <- function(path, trace = TRUE, …) {
for (nm in list.files(path, pattern = “\\.[Rr]$”)) {
if(trace) cat(nm,”:”)
source(file.path(path, nm), …)
if(trace) cat(“\n”)
}
}
sourceDir <- function(path, trace = TRUE, …) {
for (nm in list.files(path, pattern = "\\.[Rr]$")) {
if(trace) cat(nm,":")
source(file.path(path, nm), …)
if(trace) cat(“\n”)
}
}
sourceDir <- function(path, trace = TRUE, ...) {
for (nm in list.files(path, pattern = "\\.[Rr]$")) {
if(trace) cat(nm,":")
source(file.path(path, nm), ...)
if(trace) cat(“\n”)
}
}
sourceDir <- function(path, trace = TRUE) {
for (nm in list.files(path, pattern = "\\.[Rr]$")) {
if(trace) cat(nm,":")
source(file.path(path, nm))
if(trace) cat(“\n”)
}
}
sourceDir <- function(path, trace = TRUE) {
for (nm in list.files(path, pattern = "\\.[Rr]$")) {
if(trace) cat(nm,":")
source(file.path(path, nm))
if(trace) cat("\n")
}
}
sourceDir("R/")
library(randomForest);
graphics.off()
sourceDir <- function(path, trace = TRUE) {
for (nm in list.files(path, pattern = "\\.[Rr]$")) {
if(trace) cat(nm,":")
source(file.path(path, nm))
if(trace) cat("\n")
}
}
sourceDir("R/")
rm(list=ls(all=TRUE))
library(randomForest);
graphics.off()
sourceDir <- function(path, trace = TRUE) {
for (nm in list.files(path, pattern = "\\.[Rr]$")) {
if(trace) cat(nm,":")
source(file.path(path, nm))
if(trace) cat("\n")
}
}
sourceDir("R/")
sourceDir <- function(path, trace = TRUE) {
for (nm in list.files(path, pattern = "\\.[Rr]$")) {
if(trace) cat(nm)
source(file.path(path, nm))
if(trace) cat("\n")
}
}
sourceDir("R/")
thisData <- c("iris.data")
thisData
thisData <- c("iris.data")
path <- paste(getwd(), "/data/",thisData,sep=""); #musk vehicle is good austra
path
X <- read.table(path,header=TRUE,sep = ",")
X
X[X[,]=="?"] <- NA
X
X <- na.roughfix(X)#Impute Missing Values by median/mode
Y <-  X[,ncol(X)]
X <- X[,-ncol(X)]
rf <- randomForest(trainX, as.factor(trainY),ntree=100)
rf <- randomForest(X, as.factor(Y),ntree=100)
rf
treeList <- RF2List(rf)
ix <- sample(1:length(ruleExec),min(2000,length(ruleExec))) #randomly select 2000 rules
ruleExec <- ruleExec[ix,,drop=FALSE]
ruleMetric <- getRuleMetric(ruleExec,trainX,trainY)
ruleMetric <- pruneRule(ruleMetric,trainX,trainY,typeDecay = 1)
ruleMetric <- unique(ruleMetric)
treeList <- RF2List(rf)
ruleExec <- extractRules(treeList,trainX)
ruleExec <- unique(ruleExec) # remove same rules. NOTE: for variable interaction analysis, you should NOT perform this step
ix <- sample(1:length(ruleExec),min(2000,length(ruleExec))) #randomly select 2000 rules
ruleExec <- ruleExec[ix,,drop=FALSE]
sourceDir("devR/")
#Orig RF and calculate the importance
rf <- randomForest(X, as.factor(Y),ntree=100)
treeList <- RF2List(rf)
ruleExec <- extractRules(treeList,X)
ruleExec <- unique(ruleExec) # remove same rules. NOTE: for variable interaction analysis, you should NOT perform this step
ix <- sample(1:length(ruleExec),min(2000,length(ruleExec))) #randomly select 2000 rules
ruleExec <- ruleExec[ix,,drop=FALSE]
ruleMetric <- getRuleMetric(ruleExec,X,Y)
ruleMetric
ruleMetric <- selectRuleRRF(ruleMetric,X,Y)
library(RRF);
ruleMetric <- selectRuleRRF(ruleMetric,X,Y)
ruleMetric
cvob1=cv.glmnet(as.matrix(X,Y, type.measure="mae")
)
library(glmnet)
cvob1=cv.glmnet(as.matrix(X,Y, type.measure="mae"))
X
cvob1=cv.glmnet(as.matrix(X),Y, type.measure="mae")
cvob1=cv.glmnet(as.matrix(X),Y, type.measure="mae")
Y
cvob1=cv.glmnet(as.matrix(X),Y, type.measure="mae",family="multinomial")
cvob1
glmModel <- cv.glmnet(as.matrix(X),Y, type.measure="mae",family="multinomial")
coef <- coef(glmModel)
coef
pred <- predict(glmModel,as.matrix(X[,])) #ixTest
pred
length(unique(Y))
if (length(unique(Y)) > 2) stop("Currently only support two class problem!")
thisData <- c("german.data")
path <- paste(getwd(), "/data/",thisData,sep=""); #musk vehicle is good austra
X <- read.table(path,header=TRUE,sep = ",")
X[X[,]=="?"] <- NA
X <- na.roughfix(X)#Impute Missing Values by median/mode
Y <-  X[,ncol(X)]
X <- X[,-ncol(X)]
#Orig RF and calculate the importance
rf <- randomForest(X, as.factor(Y),ntree=100)
treeList <- RF2List(rf)
ruleExec <- extractRules(treeList,X)
ruleExec <- unique(ruleExec) # remove same rules. NOTE: for variable interaction analysis, you should NOT perform this step
ix <- sample(1:length(ruleExec),min(2000,length(ruleExec))) #randomly select 2000 rules
ruleExec <- ruleExec[ix,,drop=FALSE]
ruleMetric <- getRuleMetric(ruleExec,X,Y)
ruleMetric <- selectRuleRRF(ruleMetric,X,Y)
# cvob1=cv.glmnet(as.matrix(X[,,drop=FALSE]),Y, type.measure="mae")
library(glmnet)
if (length(unique(Y)) > 2) stop("Currently only support two class problem!")
glmModel <- cv.glmnet(as.matrix(X),Y, type.measure="mae",family="multinomial")
coef <- coef(glmModel)
pred <- predict(glmModel,as.matrix(X[,])) #ixTest
glmModel <- cv.glmnet(as.matrix(X),Y, type.measure="mae")
as.matrix(X)
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,target)
ruleI
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,target)
target
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
ruleI
ruleI[1:10,]
ruleI[1:10,1:4]
ruleI[1,1]
ruleI[1:2,1:2]
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
glmModel <- cv.glmnet(as.matrix(ruleI),as.factor(target), type.measure="mae")
glmModel <- cv.glmnet(as.matrix(ruleI),as.factor(Y), type.measure="mae")
as.factor(Y)
Y
as.numeric(Y)
class(Y)
is.numeric(Y)
Y <- as.numeric(Y)
if (length(unique(Y)) > 2) stop("Currently only support two class problem!")
if (is.numeric(Y) == FALSE) stop("Target variable needs to be numerical!")
Y <- as.numeric(Y)
if (is.numeric(Y) == FALSE) stop("Target variable needs to be numerical!")
# if (length(unique(Y)) > 2) stop("Currently only support two class problem!")
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
glmModel <- cv.glmnet(as.matrix(ruleI),as.factor(Y), type.measure="mae")
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
glmModel <- cv.glmnet(as.matrix(ruleI),Y, type.measure="mae")
glmModel
coef <- coef(glmModel)
coef
as.numeric(coef)
coef[1]
coef[2]
coef[3]
att(coef)
attr(coef)
atts(coef)
summary(coef)
names(coef)
summary(coef)
rownames(coef)
rownames(coef)
as.numeric(coef)
rownames(coef)
rownames(coef)
names(coef) == '(Intercept)'
which( names(coef) == '(Intercept)' )
names(coef)
coef <- coef(glmModel)
names(coef)
coef
which( colnames(coef) == '(Intercept)' )
colnames(coef)
rownames(coef)
which( rownames(coef) == '(Intercept)' )
ruleI
ruleI[1:3,]
colnamesSave <- colnames(ruleI)
colnamesSave
paste0("R",1:ncol(ruleI))
colnames(ruleI) <- paste0("R",1:ncol(ruleI))
glmModel <- cv.glmnet(as.matrix(ruleI),Y, type.measure="mae")
coef <- coef(glmModel)
coef
colnames(ruleI) <- paste0("_",1:ncol(ruleI))
glmModel <- cv.glmnet(as.matrix(ruleI),Y, type.measure="mae")
coef <- coef(glmModel)
coef
which( grepl("_",rownames(coef) )
)
rownames(coef)[which( grepl("_",rownames(coef) ))]
coef[which( grepl("_",rownames(coef) ))]
ix.rules <- which( grepl("_",rownames(coef) ))
ix.rules
as.numeric(coef) != 0
feaSet <- which (as.numeric(coef) != 0)
feaSet
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
colnamesSave <- colnames(ruleI)
colnames(ruleI) <- paste0("R_",1:ncol(ruleI))
glmModel <- cv.glmnet(as.matrix(ruleI),Y, type.measure="mae")
coef <- coef(glmModel)
ix.rules <- which( grepl("R_",rownames(coef) ))
feaSet <- which (as.numeric(coef) != 0)
coefReg
feaSet
ix.rules <- which( grepl("R_",rownames(coef) ))
feaSet <- which (as.numeric(coef[ix.rules]) != 0)
ix.rules <- which( grepl("R_",rownames(coef) ))
ix.non.zero <- which (as.numeric(coef) != 0)
ix.non.zero
intersect(ix.rules, ix.non.zero)
rownames(coef)[ix.effective.rules]
ix.rules <- which( grepl("R_",rownames(coef) ))
ix.non.zero <- which (as.numeric(coef) != 0)
ix.effective.rules <- intersect(ix.rules, ix.non.zero)
rownames(coef)[ix.effective.rules]
colnamesSave
rownames(coef)[ix.effective.rules]
coef[ix.effective.rules]
coef[ix.effective.rules,]
X <- read.table("nps_full.csv",header=TRUE,sep = ",")
X <- read.csv("nps_full.csv",header=TRUE)
X
summary(X)
X[X[,]=="?"] <- 0
X <- na.roughfix(X)
library(randomForest);
X <- na.roughfix(X)
X
summary(X)
sourceDir <- function(path, trace = TRUE) {
for (nm in list.files(path, pattern = "\\.[Rr]$")) {
if(trace) cat(nm)
source(file.path(path, nm))
if(trace) cat("\n")
}
}
sourceDir("devR/")
nRep <- 10 # in the paper it is set to be 100
thisData <- c("german.data")
path <- paste(getwd(), "/data/",thisData,sep=""); #musk vehicle is good austra
X <- read.table(path,header=TRUE,sep = ",")
X[X[,]=="?"] <- NA
X <- na.roughfix(X)#Impute Missing Values by median/mode
Y <-  X[,ncol(X)]
X <- X[,-ncol(X)]
#Orig RF and calculate the importance
rf <- randomForest(X, as.factor(Y),ntree=100)
treeList <- RF2List(rf)
ruleExec <- extractRules(treeList,X)
ruleExec <- unique(ruleExec) # remove same rules. NOTE: for variable interaction analysis, you should NOT perform this step
ix <- sample(1:length(ruleExec),min(2000,length(ruleExec))) #randomly select 2000 rules
ruleExec <- ruleExec[ix,,drop=FALSE]
ruleMetric <- getRuleMetric(ruleExec,X,Y)
ruleMetric <- selectRuleRRF(ruleMetric,X,Y)
# cvob1=cv.glmnet(as.matrix(X[,,drop=FALSE]),Y, type.measure="mae")
library(glmnet)
Y <- as.numeric(Y)
if (is.numeric(Y) == FALSE) stop("Target variable needs to be numerical!")
# if (length(unique(Y)) > 2) stop("Currently only support two class problem!")
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
colnamesSave <- colnames(ruleI)
colnames(ruleI) <- paste0("R_",1:ncol(ruleI))
glmModel <- cv.glmnet(as.matrix(ruleI),Y, type.measure="mae")
coef <- coef(glmModel)
coef
ix.rules <- which( grepl("R_",rownames(coef) ))
ix.non.zero <- which (as.numeric(coef) != 0)
ix.effective.rules <- intersect(ix.rules, ix.non.zero)
ix.effective.rules <- intersect(ix.rules, ix.non.zero)
coef[ix.effective.rules,]
coef
dim(ruleMetric)
coef[ix.effective.rules,]
ix.effective.rules
coef[ix.effective.rules,]
names( coef[ix.effective.rules,] )
gsub("R_","",names( coef[ix.effective.rules,] ))
coef[ix.effective.rules,]
rWeights <- cbind(ruleIx,coef[ix.effective.rules,])
ruleIx <- gsub("R_","",names( coef[ix.effective.rules,] ))
rWeights <- cbind(ruleIx,coef[ix.effective.rules,])
rWeights
rownames(rWeights) <- NULL
rWeights
rWeights <- cbind(ix=ruleIx, imp=coef[ix.effective.rules,])
rWeights <- cbind(ix=as.numeric(ruleIx), imp=as.numeric(coef[ix.effective.rules,]) )
rWeights
rownames(rWeights) <- NULL
rWeights
rWeights <- rWeights[order(rWeights$ix),]
rWeights$ix
rWeights
order(rWeights[,"ix"])
rWeights <- rWeights[order(rWeights[,"ix"]),]
rWeights
rWeights <- rWeights[order(rWeights[,"imp"]),]
rWeights
rWeights <- rWeights[order(-rWeights[,"imp"]),]
rWeights
rWeights <- rWeights[order(abs(rWeights[,"imp"]),]
rWeights <- rWeights[order(abs(rWeights[,"imp"])),]
rWeights
rWeights <- rWeights[order(-abs(rWeights[,"imp"])),]
rWeights
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
colnamesSave <- colnames(ruleI)
colnames(ruleI) <- paste0("R_",1:ncol(ruleI))
glmModel <- cv.glmnet(as.matrix(ruleI),Y, type.measure="mae")
coef <- coef(glmModel)
coef
# grepl("^[^_]+_2",s)
ix.rules <- which( grepl("R_",rownames(coef) ))
ix.non.zero <- which (as.numeric(coef) != 0)
ix.effective.rules <- intersect(ix.rules, ix.non.zero)
ruleIx <- gsub("R_","",names( coef[ix.effective.rules,] ))
rWeights <- cbind(ix=as.numeric(ruleIx), imp=as.numeric(coef[ix.effective.rules,]) )
rownames(rWeights) <- NULL
rWeights <- rWeights[order(-abs(rWeights[,"imp"])),]
rWeights
rWeights$ix
ruleMetric[1:3,]
as.numeric(ruleIx)
imp <- as.numeric(coef[ix.effective.rules,])
imp
ruleSet <- cbind(ruleMetric[feaSet,,drop=FALSE],imp=imp[feaSet])
feaSet <- as.numeric(ruleIx)
imp <- as.numeric(coef[ix.effective.rules,])
ruleSet <- cbind(ruleMetric[feaSet,,drop=FALSE],imp=imp[feaSet])
ruleSet
feaSet
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
colnamesSave <- colnames(ruleI)
colnames(ruleI) <- paste0("R_",1:ncol(ruleI))
glmModel <- cv.glmnet(as.matrix(ruleI),Y, type.measure="mae")
coef <- coef(glmModel)
rf <- randomForest(X, as.factor(Y),ntree=100)
treeList <- RF2List(rf)
ruleExec <- extractRules(treeList,X)
ruleExec <- unique(ruleExec) # remove same rules. NOTE: for variable interaction analysis, you should NOT perform this step
ix <- sample(1:length(ruleExec),min(2000,length(ruleExec))) #randomly select 2000 rules
ruleExec <- ruleExec[ix,,drop=FALSE]
ruleMetric <- getRuleMetric(ruleExec,X,Y)
ruleMetric <- selectRuleRRF(ruleMetric,X,Y)
ruleMetric[1:3,]
Y <- as.numeric(Y)
if (is.numeric(Y) == FALSE) stop("Target variable needs to be numerical!")
ruleI = sapply(ruleMetric[,"condition"],rule2Table,X,Y)
colnamesSave <- colnames(ruleI)
colnames(ruleI) <- paste0("R_",1:ncol(ruleI))
glmModel <- cv.glmnet(as.matrix(ruleI),Y, type.measure="mae")
coef <- coef(glmModel)
# grepl("^[^_]+_2",s)
ix.rules <- which( grepl("R_",rownames(coef) ))
ix.non.zero <- which (as.numeric(coef) != 0)
ix.effective.rules <- intersect(ix.rules, ix.non.zero)
ruleIx <- gsub("R_","",names( coef[ix.effective.rules,] ))
feaSet <- as.numeric(ruleIx)
feaSet
coef[ix.effective.rules,]
imp <- as.numeric(coef[ix.effective.rules,])
imp
ruleSet <- cbind(ruleMetric[feaSet,,drop=FALSE],imp=imp)
ruleSet
ruleSet <- cbind(ruleMetric[feaSet,,drop=FALSE],imp=imp)
ix = order(as.numeric(ruleSet[,"imp"]),
decreasing=TRUE)
ruleSet <- ruleSet[ix,,drop=FALSE]
ruleSet
Y
ruleMetricLinear <- ruleSelectLinear(ruleExec,X,Y)
source("selectRuleLinear.R")
ruleMetricLinear <- ruleSelectLinear(ruleExec,X,Y)
source("selectRuleLinear.R")
source("devR/selectRuleLinear.R")
ruleMetricLinear <- ruleSelectLinear(ruleExec,X,Y)
source("devR/selectRuleLinear.R")
ruleMetricLinear <- ruleSelectLinear(ruleExec,X,Y)
source("devR/selectRuleLinear.R")
ruleMetricLinear <- ruleSelectLinear(ruleExec,X,Y)
source("devR/selectRuleLinear.R")
ruleMetricLinear <- ruleSelectLinear(ruleExec,X,Y)
ruleMetricLinear
